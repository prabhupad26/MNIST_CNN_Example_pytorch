{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(9216,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x,dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch,batch_idx * len(data),len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output,target,reduction='sum').item()\n",
    "            pred = output.argmax(dim = 1, keepdim= True)\n",
    "            correct += pred.eq(target.view_datasets.as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss : {:.4f}, Accuracy : {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.326635\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.605359\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.985838\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.270249\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.424067\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.250919\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.360150\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.086691\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.414943\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.383202\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.303096\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.319519\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.100897\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.103377\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.110044\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.201652\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.239588\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.082468\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.090130\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.150275\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.293817\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.123667\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.241965\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.238973\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.188846\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.201100\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.032782\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.081002\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.043307\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.089103\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.131364\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.106753\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.085648\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.276598\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.087940\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.103673\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.060788\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.040335\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.049667\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.074154\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.148090\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.023051\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.175500\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.114627\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.045646\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.036748\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.055753\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.067013\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.131640\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.140060\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.189593\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.083574\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.072416\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.026111\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.011627\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.022921\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.144070\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.154627\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.122709\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.039049\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.054293\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.140082\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.025660\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.054587\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.021996\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.006691\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.012068\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.068453\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.080760\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.067627\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.141270\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.008996\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.091484\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.041196\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.007467\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.123201\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.492403\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.117898\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.078970\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.002861\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.143357\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.030359\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.064502\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.010885\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.007970\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.001376\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.012967\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.061417\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.021904\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.115909\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.058356\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.025334\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.060213\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.064782\n",
      "\n",
      "Test set: Average loss : 0.0535, Accuracy : 9826/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=True, download= True,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,),(0.3081,))])),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data',train=False,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])),\n",
    "    batch_size=1000,shuffle=True)\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(),lr = 1.0)\n",
    "# scheduler = StepLR(optimizer,step_size=1,gamma=0.7)\n",
    "train(model,train_loader,optimizer,1)\n",
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    print(image.shape)\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "images,labels = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(images[:1])\n",
    "pred = logits.argmax(dim = 1, keepdim= True)\n",
    "view_classify(images,torch.exp(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
